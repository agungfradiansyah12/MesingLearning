{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM7iu/1UONgt2YdbW1/raRi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/agungfradiansyah12/MesingLearning/blob/main/jb13MesinLearningANN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRAKTIKUM 1**"
      ],
      "metadata": {
        "id": "IDS4bt3MGAv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 2\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Hitung error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"Epoch {epoch}, Loss: {loss}\")\n",
        "\n",
        "# Output akhir\n",
        "print(\"Prediksi:\")\n",
        "print(a2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cin6pB6zGf6D",
        "outputId": "a93cd2e3-9b0f-4863-9f0a-75c3f77c9808"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Loss: 0.29721944871864403\n",
            "Epoch 1000, Loss: 0.202119189995475\n",
            "Epoch 2000, Loss: 0.15080723917407415\n",
            "Epoch 3000, Loss: 0.04577852115867572\n",
            "Epoch 4000, Loss: 0.01585113245334869\n",
            "Epoch 5000, Loss: 0.008605568107505568\n",
            "Epoch 6000, Loss: 0.005715135250086429\n",
            "Epoch 7000, Loss: 0.004216873174590422\n",
            "Epoch 8000, Loss: 0.003315252928276054\n",
            "Epoch 9000, Loss: 0.002718504574342328\n",
            "Prediksi:\n",
            "[[0.0418861 ]\n",
            " [0.95011894]\n",
            " [0.95009416]\n",
            " [0.04954994]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ubah jumlah neuron hidden layer menjadi 3"
      ],
      "metadata": {
        "id": "svf2WrtDIIRl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hidden layer = 3 neuron"
      ],
      "metadata": {
        "id": "YSJSq3SfIkaw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "# Parameter\n",
        "input_size = 2\n",
        "hidden_size = 3   # DIGANTI JADI 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "# Inisialisasi bobot\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "# Fungsi aktivasi\n",
        "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_derivative(x): return x * (1 - x)\n",
        "\n",
        "# Training\n",
        "for epoch in range(10000):\n",
        "    # Forward pass\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = sigmoid(z1)\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    # Error\n",
        "    error = y - a2\n",
        "\n",
        "    # Backpropagation\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * sigmoid_derivative(a1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    # Update bobot\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"[SIGMOID] Epoch {epoch} - Loss: {loss}\")\n",
        "\n",
        "print(\"\\nPrediksi (SIGMOID):\")\n",
        "print(a2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwRNKX2WIQZ8",
        "outputId": "6770ceb5-97b9-4e9d-b9c2-6fcef3a940d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SIGMOID] Epoch 0 - Loss: 0.254754251586372\n",
            "[SIGMOID] Epoch 1000 - Loss: 0.16904186094503293\n",
            "[SIGMOID] Epoch 2000 - Loss: 0.036185615489170306\n",
            "[SIGMOID] Epoch 3000 - Loss: 0.012916988976960184\n",
            "[SIGMOID] Epoch 4000 - Loss: 0.007198077079532317\n",
            "[SIGMOID] Epoch 5000 - Loss: 0.004849764912543738\n",
            "[SIGMOID] Epoch 6000 - Loss: 0.003610544104206078\n",
            "[SIGMOID] Epoch 7000 - Loss: 0.0028560303693920316\n",
            "[SIGMOID] Epoch 8000 - Loss: 0.0023525192649117813\n",
            "[SIGMOID] Epoch 9000 - Loss: 0.001994456536443504\n",
            "\n",
            "Prediksi (SIGMOID):\n",
            "[[0.02313734]\n",
            " [0.95975884]\n",
            " [0.95611357]\n",
            " [0.05320689]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Menggunakan ReLU"
      ],
      "metadata": {
        "id": "J2ln-4p0IZCV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Dataset XOR\n",
        "X = np.array([[0,0],[0,1],[1,0],[1,1]])\n",
        "y = np.array([[0],[1],[1],[0]])\n",
        "\n",
        "input_size = 2\n",
        "hidden_size = 3\n",
        "output_size = 1\n",
        "lr = 0.1\n",
        "\n",
        "W1 = np.random.randn(input_size, hidden_size)\n",
        "b1 = np.zeros((1, hidden_size))\n",
        "W2 = np.random.randn(hidden_size, output_size)\n",
        "b2 = np.zeros((1, output_size))\n",
        "\n",
        "def relu(x): return np.maximum(0, x)\n",
        "def relu_derivative(x): return (x > 0).astype(float)\n",
        "\n",
        "def sigmoid(x): return 1 / (1 + np.exp(-x))\n",
        "def sigmoid_derivative(x): return x * (1 - x)\n",
        "\n",
        "for epoch in range(20000):\n",
        "    # Forward\n",
        "    z1 = np.dot(X, W1) + b1\n",
        "    a1 = relu(z1)  # RELU\n",
        "    z2 = np.dot(a1, W2) + b2\n",
        "    a2 = sigmoid(z2)\n",
        "\n",
        "    error = y - a2\n",
        "\n",
        "    # Backprop\n",
        "    d_a2 = error * sigmoid_derivative(a2)\n",
        "    d_W2 = np.dot(a1.T, d_a2)\n",
        "    d_b2 = np.sum(d_a2, axis=0, keepdims=True)\n",
        "\n",
        "    d_a1 = np.dot(d_a2, W2.T) * relu_derivative(z1)\n",
        "    d_W1 = np.dot(X.T, d_a1)\n",
        "    d_b1 = np.sum(d_a1, axis=0, keepdims=True)\n",
        "\n",
        "    W1 += lr * d_W1\n",
        "    b1 += lr * d_b1\n",
        "    W2 += lr * d_W2\n",
        "    b2 += lr * d_b2\n",
        "\n",
        "    if epoch % 2000 == 0:\n",
        "        loss = np.mean(np.square(error))\n",
        "        print(f\"[RELU] Epoch {epoch} - Loss: {loss}\")\n",
        "\n",
        "print(\"\\nPrediksi (RELU):\")\n",
        "print(a2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5gmA73DIrsq",
        "outputId": "d4c9c5b4-9cd9-4d56-f67a-66bfd05373fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[RELU] Epoch 0 - Loss: 0.31333007486529896\n",
            "[RELU] Epoch 2000 - Loss: 0.25122810945283863\n",
            "[RELU] Epoch 4000 - Loss: 0.2505404110115625\n",
            "[RELU] Epoch 6000 - Loss: 0.25033996951563947\n",
            "[RELU] Epoch 8000 - Loss: 0.25024619317464003\n",
            "[RELU] Epoch 10000 - Loss: 0.25019225081734575\n",
            "[RELU] Epoch 12000 - Loss: 0.2501573457022262\n",
            "[RELU] Epoch 14000 - Loss: 0.2501329732731773\n",
            "[RELU] Epoch 16000 - Loss: 0.25011502302010813\n",
            "[RELU] Epoch 18000 - Loss: 0.25010126588092507\n",
            "\n",
            "Prediksi (RELU):\n",
            "[[0.01786797]\n",
            " [0.9952869 ]\n",
            " [0.99542638]\n",
            " [0.9999996 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRAKTIKUM 2**"
      ],
      "metadata": {
        "id": "CTBgiLYrGKHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# Load dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target.reshape(-1, 1)\n",
        "\n",
        "# One-hot encoding\n",
        "encoder = OneHotEncoder(sparse=False)\n",
        "y = encoder.fit_transform(y)\n",
        "\n",
        "# Split data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Bangun model\n",
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.Dense(10, activation='relu', input_shape=(4,)),\n",
        "    tf.keras.layers.Dense(8, activation='relu'),\n",
        "    tf.keras.layers.Dense(3, activation='softmax')\n",
        "])\n",
        "\n",
        "# Kompilasi\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Latih model\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=8)\n",
        "\n",
        "# Evaluasi\n",
        "loss, acc = model.evaluate(X_test, y_test)\n",
        "print(f\"Akurasi: {acc}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "qiGu6ChxJBzE",
        "outputId": "6df49682-5d70-49b6-8edc-52cbe4f31de6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1792594454.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# One-hot encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: OneHotEncoder.__init__() got an unexpected keyword argument 'sparse'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **PRAKTIKUM 3**"
      ],
      "metadata": {
        "id": "XORrbroAGOD6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **TUGAS PRAKTIKUM**"
      ],
      "metadata": {
        "id": "eOFTAOTxGSTc"
      }
    }
  ]
}